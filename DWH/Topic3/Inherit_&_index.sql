--Task 1 unlogged tables

create table labs.test_simple (a int, b int);

--select * from labs.test_simple;


-- It takes about 0.910 s
insert into labs.test_simple values (generate_series(1,1000000));

--It takes about 4.610 s
insert into labs.test_simple values (generate_series(1,5000000));

--create table
create table labs.test_unlogged(a int,b int)

--select * from labs.test_unlogged;


--It takes about 0.889 s
insert into labs.test_unlogged values (generate_series(1,1000000));


--it takes about 4.535 s
insert into labs.test_simple values (generate_series(1,5000000));

UNLOGGED tables can indeed be faster when data durability is not required, as they do not use the WAL, saving resources and speeding up operations. In your case, the insert into the UNLOGGED table is faster due to this lack of WAL writing. However, they should be used with caution.




--Task 2 Inherits tables

--set to labs schema
SET search_path TO labs;

--create table
CREATE TABLE users(
user_id INT GENERATED BY DEFAULT AS identity PRIMARY KEY,
login VARCHAR(30))
INHERITS (labs.person);


--insert in users table
INSERT INTO users (id, name, login) VALUES (1, 'new Bob', 'NewLogin');
INSERT INTO users (id, name, login) VALUES (999, 'TestUser', 'TestLogin');

--perform selects
select * from person;
select * from users;
SELECT * FROM ONLY person;

--
--Modify data in person table, check result:
UPDATE person
SET name = 'not Bob'
where id = 1;

--modify only person table row
UPDATE only person
SET name = 'not super Bob'
where id = 1;

--Alter person table and check structure and constraints on both users and person tables:
ALTER TABLE person ADD COLUMN status integer DEFAULT 0;
ALTER TABLE person ADD CONSTRAINT status CHECK (status in (0,1)) no INHERIT;
ALTER TABLE person ADD CONSTRAINT id UNIQUE (id, name);



--Task 3 Brin vs B-Tree

--Create table test_index:
CREATE TABLE labs.test_index (
num float NOT NULL,
load_date timestamptz NOT NULL
);

select * from test_index;

--Fill the table with a lot of test data:
INSERT INTO test_index(num, load_date)
SELECT random(), x
FROM generate_series('2017-01-01 0:00'::timestamptz,
'2021-12-31 23:59:59'::timestamptz, '10 seconds'::interval) x;

--Check the plan differencies:
explain analyze SELECT pg_size_pretty(pg_relation_size('test_index'));

--Check the table size:
select pg_size_pretty(pg_relation_size('test_index'));

--Perform select and check how much time it takes:
explain analyze SELECT date_trunc('year', load_date), max(num)
FROM test_index
WHERE load_date BETWEEN '2021-09-01 0:00' AND '2021-10-31 11:59:59'
GROUP BY 1
ORDER BY 1;

select * from test_index;


--create B-tree index on load_date column:
CREATE INDEX test_index_load_date_idx ON test_index (load_date);

--check how long this opertion takes
EXPLAIN ANALYZE CREATE INDEX test_index_load_date_idx ON test_index (load_date);

--check index size
SELECT pg_size_pretty(pg_relation_size('test_index_load_date_idx'));

--drop index
DROP INDEX IF EXISTS test_index_load_date_idx;



--Create BRIN Index on test_index table for load_date column

--this is index that good for columns, where values like timestamp
CREATE INDEX test_index_load_date_brin_idx ON test_index USING BRIN (load_date);

--check index size
SELECT pg_size_pretty(pg_relation_size('test_index_load_date_brin_idx'));

drop INDEX test_index_load_date_brin_idx;

drop table test_index;



--TASK 4 - GIN VS GIST


CREATE TABLE test_index AS 
SELECT id, md5(id::text) as t_hash   --md5 generiruet fiksirovanoje  128-bitnoe znachenije
FROM generate_series(1, 10000000) AS id;

select * from test_index;

--check index size
SELECT pg_size_pretty(pg_relation_size('test_index'));


--Perform select and check how much time it takes:
explain analyze SELECT * FROM test_index WHERE t_hash LIKE '%ceea167a5a%';


--Create GIST Index on test_index table for t_hash column
CREATE EXTENSION IF NOT EXISTS pg_trgm;

CREATE INDEX idx_text_index_gist ON test_index USING gist(t_hash gist_trgm_ops);

-- index size 
SELECT pg_size_pretty(pg_relation_size('idx_text_index_gist'));

DROP INDEX IF EXISTS idx_text_index_gist;


--SELECT pg_size_pretty(pg_relation_size('idx_index_gist'));


--Create GIN Index on test_index table for t_hash column
CREATE EXTENSION IF NOT EXISTS pg_trgm;

CREATE INDEX idx_text_index_gin ON test_index USING gin(t_hash gin_trgm_ops);

-- index size 
SELECT pg_size_pretty(pg_relation_size('idx_text_index_gin'));


DROP INDEX IF EXISTS idx_text_index_gist;



--TASK 5 â€“ CSV FILE AS A table

--Install file_fdw extension to database and create the SERVER to use, every FOREIGN TABLE requires a server:

CREATE EXTENSION file_fdw;  -- rashirenije kotroroje pozvoliaet rabotat s csv failami kak budto oni tablicy
CREATE SERVER test_import FOREIGN DATA WRAPPER file_fdw;

--Create the foreign table to connect to the CSV file (cities_list.csv):
CREATE FOREIGN TABLE labs.test_foreign_table
(
LatD INT,
LatM INT,
LatS INT,
NS TEXT,
LonD INT,
LonM INT,
LonS INT,
EW TEXT,
City TEXT,
State TEXT
)
SERVER test_import
OPTIONS
(
filename 'C:\Program Files\PostgreSQL\17\data\EPAM_study\cities_list.csv',
format 'csv',
header 'true',
delimiter ','
);

drop foreign table labs.test_foreign_table;

--Select data from the foreign table and count of rows.
SELECT * FROM labs.test_foreign_table;
SELECT count(*) FROM labs.test_foreign_table;

--Create Materialized view to select from this foreign table. Select from MView.
create materialized view labs.mview as
select * from labs.test_foreign_table;

select * from labs.mview;

select count(*) from labs.mview;

--I cannot not delete from materilized view
delete from labs.mview
where latd = 41 and latd = 46;


--modify csv file directly then refresh mview
REFRESH MATERIALIZED VIEW labs.mview;

select count(*) from labs.mview;

---yes it finish :)
